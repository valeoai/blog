<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation | valeo.ai blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Unsupervised domain adaptation for semantic segmentation." />
<meta property="og:description" content="Unsupervised domain adaptation for semantic segmentation." />
<link rel="canonical" href="https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html" />
<meta property="og:url" content="https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html" />
<meta property="og:site_name" content="valeo.ai blog" />
<meta property="og:image" content="https://valeoai.github.io/blog/images/advent/qualitative_results.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-07T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html"},"description":"Unsupervised domain adaptation for semantic segmentation.","@type":"BlogPosting","url":"https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html","headline":"ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation","dateModified":"2020-07-07T00:00:00-05:00","datePublished":"2020-07-07T00:00:00-05:00","image":"https://valeoai.github.io/blog/images/advent/qualitative_results.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://valeoai.github.io/blog/feed.xml" title="valeo.ai blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation | valeo.ai blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Unsupervised domain adaptation for semantic segmentation." />
<meta property="og:description" content="Unsupervised domain adaptation for semantic segmentation." />
<link rel="canonical" href="https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html" />
<meta property="og:url" content="https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html" />
<meta property="og:site_name" content="valeo.ai blog" />
<meta property="og:image" content="https://valeoai.github.io/blog/images/advent/qualitative_results.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-07T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html"},"description":"Unsupervised domain adaptation for semantic segmentation.","@type":"BlogPosting","url":"https://valeoai.github.io/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html","headline":"ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation","dateModified":"2020-07-07T00:00:00-05:00","datePublished":"2020-07-07T00:00:00-05:00","image":"https://valeoai.github.io/blog/images/advent/qualitative_results.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://valeoai.github.io/blog/feed.xml" title="valeo.ai blog" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">valeo.ai blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/projects/">Projects</a><a class="page-link" href="/blog/about/">About</a><a class="page-link" href="/blog/categories/">Tags</a><a class="page-link" href="/blog/search/">Search</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">ADVENT - Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation</h1><p class="page-description">Unsupervised domain adaptation for semantic segmentation.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-07T00:00:00-05:00" itemprop="datePublished">
        Jul 7, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#domain adaptation">domain adaptation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#semantic segmentation">semantic segmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#object detection">object detection</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#bridging-domains">Bridging domains</a></li>
<li class="toc-entry toc-h2"><a href="#approach">Approach</a></li>
<li class="toc-entry toc-h2"><a href="#direct-entropy-minimization">Direct entropy minimization</a></li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul><p><em>This post describes our <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vu_ADVENT_Adversarial_Entropy_Minimization_for_Domain_Adaptation_in_Semantic_Segmentation_CVPR_2019_paper.html">recent work</a> on unsupervised domain adaptation for semantic segmentation presented at CVPR 2019. ADVENT is a flexible technique for bridging the gap between two different domains through entropy minimization. Our work builds upon a simple observation: models trained only on source domain tend to produce over-confident, i.e., low-entropy, predictions on source-like images and under-confident, i.e., high-entropy, predictions on target-like ones. Consequently by minimizing the entropy on the target domain, we make the feature distributions from the two domains more similar. We show that our approach achieves competitive performances on standard semantic segmentation benchmarks and that it can be successfully extended to other tasks such as object detection.</em></p>

<p>Visual perception is a remarkable ability that human drivers leverage for understanding their surroundings and for supporting the multiple micro-decisions needed in traffic. Since many years, researchers have been working on mimicking this human capability by means of computer algorithms. This research field is known as computer vision and it has seen impressive progress and wide adoption. Most of the modern <em>computer vision</em> systems rely on Deep Neural Networks (DNNs) which are powerful and widely employed tools able to learn from large amounts of data and make accurate predictions. In autonomous driving, DNN-based visual perception is also at the heart of the complex architectures under intelligent cars, and supports downstream decisions of the vehicle, <em>e.g.,</em> steering, braking, signaling, etc.</p>

<p>The diversity and complexity of the situations encountered in real-world driving is tremendous. Unlike humans who can extrapolate effortlessly from previous experience in order to adapt to new environments and conditions, the scope of DNNs beyond the types of conditions and scenes seen during training is limited. For instance a model trained on data from a sunny country, would have a hard time delivering the same performance on streets with mixed weather conditions in a different country (with different urban architecture, furniture, vegetation, types of cars and pedestrian appearance and clothing). Similarly a model trained on a particular type of camera, is expected to see a drop in performance with images coming from a camera with different specifications. This difference between environments that leads to performance drops is referred to as <em>domain gap</em>.</p>

<h2 id="bridging-domains">
<a class="anchor" href="#bridging-domains" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bridging domains</h2>

<p>We can resort to two options for narrowing the domain gap: (i) annotate more data; (ii) leverage the experience acquired on an initial environment and transfer it to the new environment. More annotated data has been shown to always improve performance of DNNs <a class="citation" href="#sun2017revisiting">(Sun et al., 2017)</a>. However the labeling process brings a significant financial and temporal burden. The time required for a high-quality annotation, such as the ones from the popular Cityscapes dataset is âˆ¼90 minutes per image <a class="citation" href="#cordts2016cityscapes">(Cordts et al., 2016)</a>. The amount of images required to train high performance DNNs typically counts in hundreds of thousands. The acquisition of diverse data across seasons and weather conditions adds up even more time. It makes then sense to look for a solution elsewhere and the second option seems now more appealing, though achieving it remains technically challenging. This is actually the area of research of domain adaptation (DA) which addresses the domain-gap problem by transferring knowledge from a source domain (with full annotations) to a target domain (with fewer annotations if any), aiming to reach good performances on target samples. DA has consistently attracted interest from different communities across years <a class="citation" href="#csurka2017domain">(Csurka, 2017)</a>.</p>

<p>Here we are working on <em>Unsupervised DA</em> (UDA), which is a more challenging task where we have access to labeled source samples and only unlabeled target samples. We use as source, data generated by a simulator or video game engine, while for target we consider real-data from car-mounted cameras. In <em>Figure 1</em> we illustrate the difficulty of this task and the impact of our UDA technique, ADVENT.</p>

<p><img src="/blog/images/advent/advent_teaser.png" alt="" title="Figure 1: Proposed entropy-based unsupervised domain adaptation for semantic segmentation. The top two rows show results on source and target domain scenes of the model trained without adaptation. The bottom row shows the result on the same target domain scene of the model trained with entropy-based adaptation. The left and right columns visualize respectively the semantic segmentation outputs and the corresponding prediction entropy maps."></p>

<p>The main approaches for UDA include discrepancy minimization between source and target feature distributions usually achieved via adversarial training  <a class="citation" href="#ganin2015unsupervised">(Ganin &amp; Lempitsky, 2015)</a>, <a class="citation" href="#tzeng2017adversarial">(Tzeng et al., 2017)</a>, self-training with pseudo-labels <a class="citation" href="#zou2018unsupervised">(Zou et al., 2018)</a> and generative approaches <a class="citation" href="#hoffman2018cycada">(Hoffman et al., 2018)</a>, <a class="citation" href="#wu2018dcan">(Wu et al., 2018)</a>.</p>

<p><em>Entropy minimization</em> has been shown to be useful for semi-supervised learning <a class="citation" href="#grandvalet2005semi">(Grandvalet &amp; Bengio, 2005)</a>, clustering <a class="citation" href="#jain2018learning">(Jain et al., 2018)</a> and more recently to domain adaptation for classification <a class="citation" href="#long2016unsupervised">(Long et al., 2016)</a>. We chose to explore entropy based UDA training to obtain competitive performance on semantic segmentation.</p>

<h2 id="approach">
<a class="anchor" href="#approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approach</h2>

<p>We present our two proposed approaches for entropy minimization using (i) an unsupervised entropy loss and (ii) adversarial training. To build our models, we start from existing semantic segmentation frameworks and add an additional network branch used for domain adaptation. <em>Figure 2</em> illustrates our architectures.</p>

<p><img src="/blog/images/advent/advent_approach.jpg" alt="" title="Figure 2: Approach overview. First, direct entropy minimization decreases the entropy of the target Pxt, which is equivalent to minimizing the sum of weighted self-information maps Ixtâ€‹â€‹. In the second approach, we use adversarial training to enforce the consistency in Px across domains. Red arrows are used for target domain, blue arrows for source."></p>

<h2 id="direct-entropy-minimization">
<a class="anchor" href="#direct-entropy-minimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Direct entropy minimization</h2>

<p>On the source domain we train our model, denoted as $F$, as usual using a supervised loss. For the target domain, we do not have annotations and we can no longer use the segmentation loss to train $F$. We notice that models trained only on source domain tend to produce over-confident predictions on source-like images and under-confident predictions on target-like ones. Motivated by this observation, we propose a supervision signal that could leverage visual information from the target samples, in spite of the lack of annotations. The objective is to constrain $F$ to produce high-confident predictions on target samples similarly to source samples. To this effect, we introduce the entropy loss $\mathcal{L}_{ent}$â€‹ to maximize directly the prediction confidence in the target domain. Here we consider the Shannon Entropy (<a href="http://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">Shannon</a>). During training, we jointly optimize the supervised segmentation loss $\mathcal{L}_{se}$ on source samples and the unsupervised entropy loss $\mathcal{L}_{ent}$â€‹â€‹ on target samples.</p>

<h2 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h2>

<ol class="bibliography">
<li><span id="sun2017revisiting">Sun, C., Shrivastava, A., Singh, S., &amp; Gupta, A. (2017). Revisiting unreasonable effectiveness of data in deep learning era. <i>Proceedings of the IEEE International Conference on Computer Vision</i>, 843â€“852.</span></li>
<li><span id="cordts2016cityscapes">Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., &amp; Schiele, B. (2016). The cityscapes dataset for semantic urban scene understanding. <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i>, 3213â€“3223.</span></li>
<li><span id="csurka2017domain">Csurka, G. (2017). <i>Domain adaptation in computer vision applications</i>. <i>8</i>.</span></li>
<li><span id="ganin2015unsupervised">Ganin, Y., &amp; Lempitsky, V. (2015). Unsupervised domain adaptation by backpropagation. <i>International Conference on Machine Learning</i>, 1180â€“1189.</span></li>
<li><span id="tzeng2017adversarial">Tzeng, E., Hoffman, J., Saenko, K., &amp; Darrell, T. (2017). Adversarial discriminative domain adaptation. <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i>, 7167â€“7176.</span></li>
<li><span id="zou2018unsupervised">Zou, Y., Yu, Z., Vijaya Kumar, B. V. K., &amp; Wang, J. (2018). Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. <i>Proceedings of the European Conference on Computer Vision (ECCV)</i>, 289â€“305.</span></li>
<li><span id="hoffman2018cycada">Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A., &amp; Darrell, T. (2018). Cycada: Cycle-consistent adversarial domain adaptation. <i>International Conference on Machine Learning</i>, 1989â€“1998.</span></li>
<li><span id="wu2018dcan">Wu, Z., Han, X., Lin, Y.-L., Gokhan Uzunbas, M., Goldstein, T., Nam Lim, S., &amp; Davis, L. S. (2018). Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation. <i>Proceedings of the European Conference on Computer Vision (ECCV)</i>, 518â€“534.</span></li>
<li><span id="grandvalet2005semi">Grandvalet, Y., &amp; Bengio, Y. (2005). Semi-supervised learning by entropy minimization. <i>Advances in Neural Information Processing Systems</i>, 529â€“536.</span></li>
<li><span id="jain2018learning">Jain, H., Zepeda, J., PÃ©rez, P., &amp; Gribonval, R. (2018). Learning a complete image indexing pipeline. <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i>, 4933â€“4941.</span></li>
<li><span id="long2016unsupervised">Long, M., Zhu, H., Wang, J., &amp; Jordan, M. I. (2016). Unsupervised domain adaptation with residual transfer networks. <i>Advances in Neural Information Processing Systems</i>, 136â€“144.</span></li>
</ol>


  </div><a class="u-url" href="/blog/domain%20adaptation/semantic%20segmentation/object%20detection/2020/07/07/test-advent-post.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>valeo.ai research blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
