<style type="text/css">

/*h1 {
    margin-top:2.5em !important;
    color: #4a788c;
    font-size: 120%;
}

h2 {
    margin-top:1.5em !important;      
    color: #4a788c;

}

h3, h4 {
    margin-top:0.5em !important;      
    color: #4a788c;

}*/

h1 {
    margin-top:0.5em !important;
    margin-bottom:0.25em !important;
}

h3 {
    margin-bottom:0.25em !important;
    margin-top:0.25em !important;
}

p {
    margin-top:1rem !important; 
    margin-bottom:1rem !important;  
    font-size: 16px;

}

/*h1, h2, h3, h4 {
    font-weight: normal !important;
    margin-bottom:0.5em !important;  
    code {
      font-size: 100%;
    }
}   
*/

 .bibtex-box {
        background-color: #eee;     
        border: 1px solid #eeeeee;
        /*border-radius: 10px ;*/
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
        margin-top:1rem; 
        word-break: normal;
    }
</style>

<h1 align="center"> Raw High-Definition Radar for Multi-Task Learning </h1>
<h3 align="center">  <a href="https://scholar.google.com/citations?user=BJcQNcoAAAAJ">Julien Rebut</a>&nbsp;&nbsp;<a href="https://arthurouaknine.github.io/">Arthur Ouaknine</a>&nbsp;&nbsp;Waqas Walik&nbsp;&nbsp;<a href="https://ptrckprz.github.io/">Patrick PÃ©rez</a></h3>

<h3 align="center"> CVPR 2022 </h3>

<div align="center">
  <p>
    
    <a href="https://arxiv.org/abs/2112.10646"><i class="far fa-file-pdf"></i> Paper</a>&nbsp;&nbsp;
    
    
    <a href="https://github.com/valeoai/RADIal"><i class="fab fa-github"></i> Code</a> &nbsp;&nbsp;
    
    
    
    
  </p>
</div>

<p><img src="../../images/publications/2022_radial/radial_teaser.png" alt="" width="100%" /></p>

<hr />

<h2 align="center"> Abstract</h2>

<p align="justify">With their robustness to adverse weather conditions and ability to measure speeds, radar sensors have been part of the automotive landscape for more than two decades. Recent progress toward High Definition (HD) Imaging radar has driven the angular resolution below the degree, thus approaching laser scanning performance. However, the amount of data a HD radar delivers and the computational cost to estimate the angular positions remain a challenge. In this paper, we propose a novel HD radar sensing model, FFT-RadNet, that eliminates the overhead of computing the range-azimuth-Doppler 3D tensor, learning instead to recover angles from a range-Doppler spectrum. FFT-RadNet is trained both to detect vehicles and to segment free driving space. On both tasks, it competes with the most recent radar-based models while requiring less compute and memory. Also, we collected and annotated 2-hour worth of raw data from synchronized automotive-grade sensors (camera, laser, HD radar) in various environments (city street, highway, countryside road). This unique dataset, nick-named RADIal for "Radar, Lidar et al.", is available at <a href="https://github.com/valeoai/RADIal">this https URL</a>.</p>

<p><br /></p>

<hr />

<h2 align="center">BibTeX</h2>
<left>
  <pre class="bibtex-box">
@inproceedings{rebut2022radial,
    title={Raw High-Definition Radar for Multi-Task Learning},
    author={Rebut, Julien and Ouaknine, Arthur and Malik, Waqas and P{\'e}rez, Patrick},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year={2022}
}</pre>
</left>

<p><br /></p>
