<style type="text/css">

/*h1 {
    margin-top:2.5em !important;
    color: #4a788c;
    font-size: 120%;
}

h2 {
    margin-top:1.5em !important;      
    color: #4a788c;

}

h3, h4 {
    margin-top:0.5em !important;      
    color: #4a788c;

}*/

h1 {
    margin-top:0.5em !important;
    margin-bottom:0.25em !important;
}

h3 {
    margin-bottom:0.25em !important;
    margin-top:0.25em !important;
}

p {
    margin-top:1rem !important; 
    margin-bottom:1rem !important;  
    font-size: 16px;

}

/*h1, h2, h3, h4 {
    font-weight: normal !important;
    margin-bottom:0.5em !important;  
    code {
      font-size: 100%;
    }
}   
*/

 .bibtex-box {
        background-color: #eee;     
        border: 1px solid #eeeeee;
        /*border-radius: 10px ;*/
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
        margin-top:1rem; 
        word-break: normal;
    }
</style>

<h1 align="center"> Learning Representations by Predicting Bags of Visual Words </h1>
<!-- Simple call of authors -->
<!-- <h3 align="center"> Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick Pérez, and Matthieu Cord </h3> -->
<!-- Alternatively you can add links to author pages -->
<h3 align="center"> <a href="https://scholar.google.com/citations?user=7atfg7EAAAAJ&amp;hl=en">Spyros Gidaris</a>&nbsp;&nbsp; <a href="https://abursuc.github.io/">Andrei Bursuc</a>&nbsp;&nbsp; <a href="https://www.csd.uoc.gr/~komod/">Nikos Komodakis</a>&nbsp;&nbsp; <a href="https://ptrckprz.github.io/">Patrick Pérez</a>&nbsp;&nbsp; <a href="http://webia.lip6.fr/~cord/">Matthieu Cord</a> </h3>

<h3 align="center"> CVPR 2020 </h3>

<div align="center">
  <p>
    
    <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Gidaris_Learning_Representations_by_Predicting_Bags_of_Visual_Words_CVPR_2020_paper.html"><i class="far fa-file-pdf"></i> Paper</a>&nbsp;&nbsp;
    
    
    <a href="https://github.com/valeoai/bownet"><i class="fab fa-github"></i> Code</a> &nbsp;&nbsp;
    
    
    
    
  </p>
</div>

<div class="publication-teaser">
    <img src="../../images/publications/bownet/bownet_teaser.jpg" alt="project teaser" />
</div>

<hr />

<h2 align="center"> Abstract</h2>

<p align="justify">Self-supervised representation learning targets to learn convnet-based image representations from unlabeled data. Inspired by the success of NLP methods in this area, in this work we propose a self-supervised approach based on spatially dense image descriptions that encode discrete visual concepts, here called visual words. To build such discrete representations, we quantize the feature maps of a first pre-trained self-supervised convnet, over a k-means based vocabulary. Then, as a self-supervised task, we train another convnet to predict the histogram of visual words of an image (i.e., its Bag-of-Words representation) given as input a perturbed version of that image. The proposed task forces the convnet to learn perturbation-invariant and context-aware image features, useful for downstream image understanding tasks. We extensively evaluate our method and demonstrate very strong empirical results, e.g., our pre-trained self-supervised representations transfer better on detection task and similarly on classification over classes "unseen" during pre-training, when compared to the supervised case.
This also shows that the process of image discretization into visual words can provide the basis for very powerful self-supervised approaches in the image domain, thus allowing further connections to be made to related methods from the NLP domain that have been extremely successful so far.</p>

<p><br /></p>

<hr />

<h2 align="center">BibTeX</h2>
<left>
  <pre class="bibtex-box">
@inproceedings{gidaris2020learning,
    title={Learning Representations by Predicting Bags of Visual Words},
    author={Gidaris, Spyros and Bursuc, Andrei and Komodakis, Nikos and P{\'e}rez, Patrick and Cord, Matthieu},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={6928--6938},
    year={2020}
}</pre>
</left>

<p><br /></p>
